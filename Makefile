.PHONY: help build start stop restart logs clean test data

# Variables
COMPOSE_FILE = docker-compose.yml
DATA_SIZE = 100000

help: ## Mostrar ayuda
	@echo "Analytics System - Comandos disponibles:"
	@echo ""
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-15s\033[0m %s\n", $1, $2}'

setup: ## Configuraci√≥n inicial del proyecto
	@echo "üîß Configurando proyecto..."
	@mkdir -p templates static src logs spark-conf
	@chmod +x start.sh
	@echo "‚úÖ Configuraci√≥n completada"

build: ## Construir contenedores
	@echo "üî® Construyendo contenedores..."
	@docker-compose -f $(COMPOSE_FILE) build

start: ## Iniciar todos los servicios
	@echo "üöÄ Iniciando servicios..."
	@docker-compose -f $(COMPOSE_FILE) up -d
	@echo "‚è≥ Esperando servicios..."
	@sleep 30
	@$(MAKE) status

stop: ## Detener todos los servicios
	@echo "üõë Deteniendo servicios..."
	@docker-compose -f $(COMPOSE_FILE) down

restart: ## Reiniciar todos los servicios
	@echo "üîÑ Reiniciando servicios..."
	@docker-compose -f $(COMPOSE_FILE) restart

status: ## Mostrar estado de servicios
	@echo "üìä Estado de servicios:"
	@docker-compose -f $(COMPOSE_FILE) ps
	@echo ""
	@echo "üåê URLs disponibles:"
	@echo "‚Ä¢ Dashboard: http://localhost:5000"
	@echo "‚Ä¢ Hadoop UI: http://localhost:9870"
	@echo "‚Ä¢ Spark Master UI: http://localhost:8080"
	@echo "‚Ä¢ Spark Worker 1 UI: http://localhost:8081"
	@echo "‚Ä¢ Spark Worker 2 UI: http://localhost:8082"

logs: ## Ver logs de todos los servicios
	@docker-compose -f $(COMPOSE_FILE) logs -f

logs-flask: ## Ver logs de Flask API
	@docker-compose -f $(COMPOSE_FILE) logs -f flask-api

logs-spark: ## Ver logs de Spark
	@docker-compose -f $(COMPOSE_FILE) logs -f spark-master spark-worker-1 spark-worker-2

logs-hadoop: ## Ver logs de Hadoop
	@docker-compose -f $(COMPOSE_FILE) logs -f namenode datanode

shell-flask: ## Acceder al shell del contenedor Flask
	@docker-compose -f $(COMPOSE_FILE) exec flask-api /bin/bash

shell-spark: ## Acceder al shell del master de Spark
	@docker-compose -f $(COMPOSE_FILE) exec spark-master /bin/bash

test-api: ## Probar endpoints de la API
	@echo "üß™ Probando API..."
	@echo "Health check:"
	@curl -s http://localhost:5000/api/health | python3 -m json.tool || echo "‚ùå API no disponible"
	@echo ""
	@echo "Stats endpoint:"
	@curl -s http://localhost:5000/api/stats | python3 -m json.tool || echo "‚ùå No hay datos cargados"

clean: ## Limpiar contenedores y vol√∫menes
	@echo "üßπ Limpiando sistema..."
	@docker-compose -f $(COMPOSE_FILE) down -v
	@docker system prune -f
	@echo "‚úÖ Sistema limpiado"

clean-data: ## Limpiar solo datos subidos
	@echo "üóëÔ∏è Limpiando datos subidos..."
	@docker-compose -f $(COMPOSE_FILE) exec namenode hdfs dfs -rm -r /user/hdfs/data/* 2>/dev/null || echo "No hay datos en HDFS"
	@echo "‚úÖ Datos limpiados"

reset: clean setup ## Reset completo del sistema
	@echo "üîÑ Reset completo realizado"

monitor: ## Monitorear recursos del sistema
	@echo "üìà Monitoreando recursos..."
	@docker stats

backup: ## Hacer backup de datos
	@echo "üíæ Creando backup..."
	@mkdir -p backups
	@tar -czf backups/data_backup_$(shell date +%Y%m%d_%H%M%S).tar.gz data/
	@echo "‚úÖ Backup creado en backups/"

# Comandos de desarrollo
dev-start: setup start ## Inicio r√°pido para desarrollo
	@echo "üöÄ Entorno de desarrollo listo"

dev-restart: ## Reinicio r√°pido para desarrollo
	@docker-compose -f $(COMPOSE_FILE) restart flask-api
	@echo "üîÑ Flask API reiniciada"

# Pruebas espec√≠ficas
test-spark: ## Probar conexi√≥n a Spark
	@echo "‚ö° Probando Spark..."
	@docker-compose -f $(COMPOSE_FILE) exec spark-master spark-submit --version

test-hadoop: ## Probar conexi√≥n a Hadoop
	@echo "üêò Probando Hadoop..."
	@docker-compose -f $(COMPOSE_FILE) exec namenode hdfs dfsadmin -report

test-workers: ## Verificar workers de Spark
	@echo "üë∑ Verificando workers de Spark..."
	@curl -s http://localhost:8080 | grep -o "worker-[0-9]*" || echo "Verificar manualmente en http://localhost:8080"

# Configuraci√≥n
config-check: ## Verificar configuraci√≥n de Spark
	@echo "üîç Verificando configuraci√≥n de Spark..."
	@echo "Contenido de spark-defaults.conf:"
	@cat spark-conf/spark-defaults.conf 2>/dev/null || echo "‚ùå Archivo no encontrado"
	@echo ""
	@echo "Verificando montaje en contenedor:"
	@docker-compose -f $(COMPOSE_FILE) exec flask-api ls -la /app/spark-conf/ 2>/dev/null || echo "‚ùå Contenedor no est√° corriendo"

# Instalaci√≥n
install: ## Instalaci√≥n completa
	@echo "üì¶ Instalaci√≥n completa del sistema..."
	@$(MAKE) setup
	@$(MAKE) build
	@$(MAKE) start
	@echo ""
	@echo "üéâ ¬°Sistema instalado y listo!"
	@echo "Ve a http://localhost:5000 para comenzar"
	@echo "Sube un archivo CSV para empezar a analizar datos"

# Informaci√≥n del sistema
info: ## Mostrar informaci√≥n del sistema
	@echo "‚ÑπÔ∏è Informaci√≥n del Sistema Analytics"
	@echo "=================================="
	@echo "Docker version: $(shell docker --version)"
	@echo "Docker Compose version: $(shell docker-compose --version)"
	@echo "Servicios configurados:"
	@echo "‚Ä¢ Flask API (Puerto 5000)"
	@echo "‚Ä¢ Hadoop NameNode (Puerto 9870)"
	@echo "‚Ä¢ Spark Master (Puerto 8080)"
	@echo "‚Ä¢ Spark Worker 1 (Puerto 8081)"
	@echo "‚Ä¢ Spark Worker 2 (Puerto 8082)"
	@echo ""
	@echo "Configuraci√≥n de recursos (por worker):"
	@echo "‚Ä¢ CPU: 2 cores m√°ximo"
	@echo "‚Ä¢ RAM: 1GB m√°ximo"
	@echo ""
	@echo "Para subir datos: Ve a http://localhost:5000 y usa la secci√≥n 'Cargar Datos'"

# Comandos para debugging
debug-spark-config: ## Mostrar configuraci√≥n actual de Spark
	@echo "üîß Configuraci√≥n de Spark en contenedores:"
	@docker-compose -f $(COMPOSE_FILE) exec spark-master printenv | grep SPARK || true
	@echo ""
	@echo "Variables de worker:"
	@docker-compose -f $(COMPOSE_FILE) exec spark-worker-1 printenv | grep SPARK || true

debug-resources: ## Mostrar uso de recursos
	@echo "üìä Uso de recursos por contenedor:"
	@docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"